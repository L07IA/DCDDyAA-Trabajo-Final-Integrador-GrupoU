# üìä DCDDyAA - Trabajo Final Integrador - Grupo U

Proyecto final de la **Diplomatura en Ciencia de Datos y An√°lisis Avanzado**  
**Predicci√≥n de abandono de clientes bancarios (Customer Churn Prediction)**  

---

## üìò Descripci√≥n del Proyecto  

El objetivo del trabajo fue **predecir la probabilidad de abandono (churn)** de clientes de un banco, utilizando un conjunto de datos con informaci√≥n **demogr√°fica, financiera y de comportamiento**.  

Se aplicaron t√©cnicas de **preprocesamiento, balanceo de clases, selecci√≥n de variables y modelado supervisado**, comparando diversos algoritmos de *Machine Learning* con enfoque interpretativo mediante **SHAP Values**.

---

## ‚öôÔ∏è Modelos Utilizados

- **Regresi√≥n Log√≠stica**
- **K-Nearest Neighbors (KNN)**
- **Random Forest**
- **XGBoost**
- **LightGBM**

---

## üß† Metodolog√≠a General

1. **An√°lisis Exploratorio de Datos (EDA):** identificaci√≥n de patrones de abandono y correlaciones.  
2. **Tratamiento de Datos:** eliminaci√≥n de variables irrelevantes, imputaci√≥n de faltantes y codificaci√≥n categ√≥rica.  
3. **Balanceo de clases:** aplicaci√≥n de **SMOTE** para corregir el desbalance entre clientes que abandonan y los que permanecen.  
4. **Entrenamiento y validaci√≥n:** divisi√≥n 80/20 y validaci√≥n cruzada estratificada (5 folds).  
5. **Evaluaci√≥n de modelos:** uso de m√©tricas AUC, precisi√≥n, recall y F1-score.  
6. **Interpretabilidad:** an√°lisis de importancia global y local con **SHAP Values**.  

---

## üìà M√©tricas Principales (AUC Test)

| Modelo                | AUC    | Observaciones |
|-----------------------|--------|----------------|
| **XGBoost**           | 0.9995 | M√°xima performance; `Complain` dominante |
| **Regresi√≥n Log√≠stica** | 0.9988 | Modelo simple, interpretable y robusto |
| **Random Forest**     | 0.9983 | Alta estabilidad y precisi√≥n |
| **LightGBM**          | 0.9980 | Mejor balance explicativo |
| **KNN**               | 0.9698 | Resultados correctos pero sensibles al escalado |

---

## üßæ Principales Conclusiones

- En todos los modelos, la variable **`Complain`** (reclamo registrado) result√≥ ser el predictor m√°s influyente del abandono.  
- Variables de **engagement** como **`IsActiveMember`**, **`NumOfProducts`** y **`Satisfaction Score`** mostraron un peso importante, especialmente en modelos no lineales.  
- Los valores de **AUC** obtenidos (‚âà 0.99) son excepcionalmente altos, lo que sugiere la presencia de variables con fuerte poder discriminatorio.  
  Se recomienda validar con datos reales de una instituci√≥n bancaria para confirmar la robustez del modelo.  
- Los **SHAP Values** permitieron explicar el impacto global y local de cada variable, destacando que **`Complain`**, **`Age`** e **`IsActiveMember`** son los principales impulsores del abandono.

---

## üß© Requisitos y Librer√≠as Utilizadas

El proyecto fue desarrollado en **Python 3.10** utilizando las siguientes librer√≠as principales:

- `pandas`  
- `numpy`  
- `matplotlib`  
- `seaborn`  
- `scikit-learn`  
- `imbalanced-learn`  
- `xgboost`  
- `lightgbm`  
- `shap`  

## üöÄ Ejecuci√≥n
1. Clonar el repositorio:
   ```bash
   git clone https://github.com/L07IA/DCDDyAA-Trabajo-Final-Integrador-GrupoU.git

   pip install -r requirements.txt

   jupyter notebook DCDDyAA_TrabajoFinalIntegrador_Grupo_U.ipynb



   üë®‚Äçüíª Autor

Leandro Toledo
leandro.toledo93@email.com

üìÖ Octubre 2025
